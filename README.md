## Tan's Data Science Portfolio
#### Hi there, I'm Tan.
I was born in a small and peaceful village in Vietnam. And now, I'm a Data Analyst and a bit Data Engineer. 

I have over 7 years of experience in IT industry and nearly 6 years of working in Data Analysis, Data Reporting and DWH field. I am also an innovation-oriented, open, responsible DA, DE with good leadership skill.

Feel free to reach out to me via my personal email thientannguyen209@gmail.com.

I share my humble data science portfolio below and I would love to hear your comments, suggestions to make it better.

Thanks a million and hope to see you soon. 

Peace!

### [Project 1: Basic Data Cleaning wih Python using Chicago Food Inspections dataset](https://github.com/TanThienNguyenVN/Project1_Python_DataCleaning_ChicagoFoodInspections)
- This project was done while I was studying Programming module of MSc in Data Science course in SETU, Ireland
- In this notebook, I will practice the basics of Python using Python's built-in data structures: lists, dictionaries, tuples and sets using an online tutorial video https://www.youtube.com/watch?v=j6VSAsKAj98 made by David Beazley at the talk from the 2016 PyData Conference in Chicago, USA as a reference.
- This basic notebook will help me to see how Python can be used to automate powerful data manipulations with quite big data source excel file (~250MB)
- There are some changes being made to retrieve more information
- The notebook will be presented as a story so that we can easily follow up.

### [Project 2: Web Scraping with Python from Canadian Prime Ministers Wikipage](https://github.com/TanThienNguyenVN/Project2_Python_WebScraping_CanadianPrimeMinisters)
- This project was done while I was studying Programming module of MSc in Data Science course in SETU, Ireland
- Although a lot of raw data is available in CSV, JSON, XML, and other "standard" formats, an awful lot of published data resides within webpages, embedded within HTML markup. Developing strategies and techniques for extracting usable data from raw HTML is an important skill.
- This basic notebook will help me to improve and combine SQL and database skills, as well as writing more complex Python code.
- Despite we can absolutely use Pandas and other libraries for scraping data, I will use Soup in this project.
- There are three main parts in this project:
  - 01.Create MariaDB database to store scraped data including create database, schema, table, view, user, grant access,
  - 02.Use Soup to scrap the data from Wiki page https://en.wikipedia.org/wiki/List_of_prime_ministers_of_Canada
  - 03.Use the data in database to answer some questions provided in the notebook

### [Project 3: Dynamic Web Data Analysis with Python using Covid19 data on web](https://github.com/TanThienNguyenVN/Project3_Python_DynamicWebDataAnalysis_Covid19)
- This project was done while I was studying Programming module of MSc in Data Science course in SETU, Ireland
- Cleaning, rearranging, mutating, and processing data is all well and good, but – at the end of the day we need to be able to produce and publish outcomes. Creating visualisations is an excellent example of this output, and arranging for the publication of visualisations is key, too. Targetting the WWW as a visualisation delivery mechanism ensures the widest audience for our output. Enabling the dynamic creation of visualisations via a web-based application can also enhance interactions with published outcomes. This project will explores the technologies and techniques used to enable such publications.
- Dataset which is used in this project is downloadable from the Irish Government’s Covid-19 dataset site.
- There are three main parts in this project: 
   - 01.Exploratory Data Analysis using Pandas (Load the data, Clean up the data, and Tidy the data)
   - 02.Visualize the data using Pandas, Numpy and Plotly
   - 03.Create an interactive, dynamic web application which showcases the visualisations from Part 02 using Dash, a micro-web framework.

### [Project 4: Sentiment Analysis with Python and NLP using Amazon Software Reviews](https://github.com/TanThienNguyenVN/Project4_PythonNLP_SentimentAnalysis_AmazonSoftwareReviews)
- This project was done while I was studying Data Analytics and Algorithms module of MSc in Data Science course in SETU, Ireland
- This project focuses on customer sentiment analysis using Amazon Review Data on Software products to understand customer feelings about the brands and products through their reviews.
- The project is implemented based on the CRISP-DM model through 5 phases, including Business Understanding, Data Understanding, Data Preparation, Modeling, and Evaluation. All the phases will be implemented using NLTK and Scikit-learn in Python.
- There are four main parts in this project:
- In my project, four notebooks are created to perform all CRISP-DM phases:
   - 01.Main Notebook : Main report, Business Objectives, Data Mining goals and the summary of the project
   - 02.Data Understanding : Data Collection, Data Wrangling, EDA
   - 03.Data Preparation : Data Cleaning, Data Normalization, WordCloud
   - 04.Modeling and Evaluation : Data Preprocessing, Modeling and Evaluation

### Project 5: R - Data Analysis and Visualization - World Economic Sectors
This project was done while I was studying Data Visualization and Storytelling module of MSc in Data Science course in SETU, Ireland

### Project 6: R - Statistical Analysis - Heart Disease
This project was done while I was studying Statistics for Data Science module of MSc in Data Science course in SETU, Ireland

### Project 7: Hadoop-Hive-Spark - Infrastructure as Code (IaC)
This project was done while I was studying BigData Infrastructure module of MSc in Data Science course in SETU, Ireland
